{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from sklearn.utils import shuffle\n",
    "from IPython.display import clear_output\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "df=pd.read_csv('sample_images/fer2013.csv', sep=',',header=0)\n",
    "df_train=df[df['Usage']=='Training']\n",
    "df_test=df[df['Usage']!='Training']\n",
    "del df\n",
    "\n",
    "def str2image(x):\n",
    "    return np.fromstring(x,sep=' ')\n",
    "\n",
    "def convertFlat2Image(df):\n",
    "    mat=df['pixels'].as_matrix()\n",
    "    r_mat=np.array([str2image(xi).reshape(48,48,1) for xi in mat])\n",
    "    return r_mat\n",
    "\n",
    "X_train=convertFlat2Image(df_train)\n",
    "X_test=convertFlat2Image(df_test)\n",
    "y_train=df_train['emotion'].as_matrix()\n",
    "y_test=df_test['emotion'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-c74e2bd4ca71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1410f3bbeb2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mImageAug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mYtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maug_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcritical_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "\n",
    "def ImageAug(Xtrain,Ytrain,aug_size=500,critical_val=1.5):\n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "    import collections\n",
    "    import numpy as np\n",
    "    print(\"Input count :\")\n",
    "    print(collections.Counter(y_train))\n",
    "    cat_dict=dict(collections.Counter(y_train))\n",
    "    max_cat=max(cat_dict.values())\n",
    "    Xtrain_aug = np.empty_like (Xtrain)\n",
    "    Xtrain_aug[:] = Xtrain\n",
    "    Ytrain_aug = np.empty_like (Ytrain)\n",
    "    Ytrain_aug[:] = Ytrain\n",
    "    for k in cat_dict:\n",
    "        total_len=len(Xtrain_aug[Ytrain_aug==k])\n",
    "        Xtrain_extra=np.empty((0,48,48,1))\n",
    "        Ytrain_extra=np.empty(0)\n",
    "        X_k=Xtrain[Ytrain==k]\n",
    "        Y_k=Ytrain[Ytrain==k]\n",
    "        datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "        datagen.fit(X_k)\n",
    "        for X_batch, y_batch in datagen.flow(X_k,Y_k, batch_size=aug_size):\n",
    "            Xtrain_extra=np.append(Xtrain_extra,X_batch,axis=0)\n",
    "            Ytrain_extra=np.append(Ytrain_extra,y_batch,axis=0)\n",
    "            total_len=total_len+aug_size\n",
    "            if max_cat/total_len<critical_val:\n",
    "                Xtrain_aug=np.append(Xtrain_aug,Xtrain_extra,axis=0)\n",
    "                Ytrain_aug=np.append(Ytrain_aug,Ytrain_extra,axis=0)\n",
    "                del Xtrain_extra\n",
    "                del Ytrain_extra\n",
    "                break\n",
    "    print(\"Output count :\")\n",
    "    print(collections.Counter(Ytrain_aug))\n",
    "    return Xtrain_aug,Ytrain_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "def error_rate(p,t):\n",
    "    return np.mean(p!=t)\n",
    "\n",
    "\n",
    "def convpool(X,W,b):\n",
    "    conv_out=tf.nn.conv2d(X,W,strides=[1,1,1,1],padding=\"SAME\")\n",
    "    conv_out=tf.nn.bias_add(conv_out,b)\n",
    "    pool_out=tf.nn.max_pool(conv_out,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "    return pool_out\n",
    "\n",
    "def convnopool(X,W,b):\n",
    "    conv_out=tf.nn.conv2d(X,W,strides=[1,1,1,1],padding=\"SAME\")\n",
    "    conv_out=tf.nn.bias_add(conv_out,b)\n",
    "#     pool_out=tf.nn.max_pool(conv_out,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "    return conv_out\n",
    "\n",
    "\n",
    "def init_filter(shape,poolsz):\n",
    "    w=np.random.randn(*shape)/np.sqrt(np.prod(shape[:-1])+shape[-1]*np.prod(shape[:-2]/np.prod(poolsz)))\n",
    "    return w.astype(np.float32)\n",
    "\n",
    "def init_dense(shape):\n",
    "    w=np.random.randn(*shape)/np.sqrt(np.sum(shape))\n",
    "    return w.astype(np.float32)\n",
    "\n",
    "from functools import partial\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer(mode=\"FAN_AVG\") # he init method\n",
    "scale=0.01\n",
    "my_dense=partial(tf.layers.dense,activation=tf.nn.elu,\n",
    "                 kernel_regularizer=tf.contrib.layers.l1_regularizer(scale),\n",
    "                 kernel_initializer=he_init)\n",
    "\n",
    "def main():\n",
    "    Xtrain_u=X_train[:28000,]/255\n",
    "    Ytrain_u=y_train[:28000]\n",
    "    Xtest=X_test[:7000,]/255\n",
    "    Ytest=y_test[:7000]\n",
    "    \n",
    "    #augmenting the data\n",
    "    Xtrain,Ytrain=ImageAug(Xtrain_u,Ytrain_u,aug_size=500,critical_val=1.5)\n",
    "    \n",
    "    n_epochs=500\n",
    "    N=Xtrain.shape[0]\n",
    "    batch_sz=100\n",
    "    n_batches=N//batch_sz\n",
    "    pool_sz=(2,2)\n",
    "\n",
    "    learning_rate=0.001\n",
    "    tf.reset_default_graph()\n",
    "    # cnn_pool layer 1\n",
    "    W1_shape=(3,3,1,10)\n",
    "    W1_init=init_filter(W1_shape,pool_sz)\n",
    "    b1_init=np.zeros(W1_shape[-1],dtype=np.float32)\n",
    "\n",
    "    # cnn_pool layer 2\n",
    "    W2_shape=(3,3,10,20)\n",
    "    W2_init=init_filter(W2_shape,pool_sz)\n",
    "    b2_init=np.zeros(W2_shape[-1],dtype=np.float32)\n",
    "    \n",
    "    pool_sz=(1,1)\n",
    "    # cnn_pool layer 3\n",
    "    W3_shape=(5,5,20,40)\n",
    "    W3_init=init_filter(W3_shape,pool_sz)\n",
    "    b3_init=np.zeros(W3_shape[-1],dtype=np.float32)\n",
    "\n",
    "    # cnn_pool layer 4\n",
    "    W4_shape=(3,3,40,80)\n",
    "    W4_init=init_filter(W4_shape,pool_sz)\n",
    "    b4_init=np.zeros(W4_shape[-1],dtype=np.float32)\n",
    "\n",
    "    X=tf.placeholder(tf.float32,shape=(None,48,48,1),name=\"X\")\n",
    "    y=tf.placeholder(tf.int64,shape=(None),name=\"y\")\n",
    "\n",
    "    with tf.name_scope(\"cnn\"):\n",
    "        with tf.device(\"/gpu:0\"):\n",
    "            W1=tf.Variable(W1_init.astype(np.float32))\n",
    "            b1=tf.Variable(b1_init.astype(np.float32))\n",
    "            W2=tf.Variable(W2_init.astype(np.float32))\n",
    "            b2=tf.Variable(b2_init.astype(np.float32)) \n",
    "            Z1=convpool(X,W1,b1)\n",
    "            Z2=convpool(Z1,W2,b2)\n",
    "            W3=tf.Variable(W3_init.astype(np.float32))\n",
    "            b3=tf.Variable(b3_init.astype(np.float32))\n",
    "            Z3=convnopool(Z2,W3,b3)\n",
    "            \n",
    "        with tf.device(\"/gpu:1\"):    \n",
    "            W4=tf.Variable(W4_init.astype(np.float32))\n",
    "            b4=tf.Variable(b4_init.astype(np.float32))\n",
    "            Z4=convnopool(Z3,W4,b4)\n",
    "\n",
    "    n_hidden1=2048\n",
    "    n_hidden2=n_hidden1\n",
    "    n_hidden3=n_hidden2//4\n",
    "    n_outputs=7\n",
    "    with tf.name_scope(\"dnn\"):\n",
    "        dropout_rate=0.4\n",
    "        training=tf.placeholder_with_default(False,shape=(),name=\"training\")\n",
    "        with tf.device(\"/gpu:1\"):\n",
    "            Z_f=tf.contrib.layers.flatten(Z4)\n",
    "\n",
    "            hidden1=my_dense(Z_f,n_hidden1,name=\"hidden1\",kernel_initializer=he_init,\n",
    "                             activation=tf.nn.elu)\n",
    "            hidden1_drop=tf.layers.dropout(hidden1,dropout_rate,training=training)\n",
    "\n",
    "            hidden2=my_dense(hidden1_drop,n_hidden2,name=\"hidden2\",kernel_initializer=he_init,\n",
    "                             activation=tf.nn.elu)\n",
    "            hidden2_drop=tf.layers.dropout(hidden2,dropout_rate,training=training)\n",
    "            \n",
    "            hidden3=my_dense(hidden2_drop,n_hidden3,name=\"hidden3\",kernel_initializer=he_init,\n",
    "                             activation=tf.nn.elu)\n",
    "            hidden3_drop=tf.layers.dropout(hidden3,dropout_rate,training=training)\n",
    "            logits=my_dense(hidden3_drop,n_outputs, kernel_regularizer=tf.contrib.layers.l1_regularizer(scale),\n",
    "                     kernel_initializer=he_init,name=\"outputs\")\n",
    "\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        xentropy=tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "        loss=tf.reduce_mean(xentropy,name=\"loss\")\n",
    "\n",
    "    with tf.name_scope(\"train\"):\n",
    "        optimizer=tf.train.MomentumOptimizer(learning_rate=learning_rate,\n",
    "                                             momentum=0.95,use_nesterov=True)\n",
    "        training_op=optimizer.minimize(loss)\n",
    "\n",
    "    with tf.name_scope(\"eval\"):\n",
    "        correct=tf.nn.in_top_k(logits,y,1)\n",
    "        accuracy=tf.reduce_mean(tf.cast(correct,tf.float32))\n",
    "\n",
    "    init=tf.global_variables_initializer()\n",
    "    saver=tf.train.Saver()\n",
    "    train_accuracy_save=[]\n",
    "    test_accuracy_save=[]\n",
    "\n",
    "    # calculate average accuracy\n",
    "    beta=0.9\n",
    "    with tf.Session() as sess:\n",
    "        init.run()\n",
    "        for epoch in range(n_epochs):\n",
    "            Xtrain,Ytrain=shuffle(Xtrain,Ytrain)\n",
    "            acc_train=1\n",
    "            for iteration in range(N//batch_sz):\n",
    "                X_batch,y_batch=(Xtrain[iteration*batch_sz:(iteration*batch_sz+batch_sz),:],\n",
    "                                 Ytrain[iteration*batch_sz:(iteration*batch_sz+batch_sz)])\n",
    "                sess.run(training_op,feed_dict={X:X_batch,y:y_batch,training:True}) # dropout=True\n",
    "                acc_train=beta*acc_train+(1-beta)*accuracy.eval(feed_dict={X:X_batch,y:y_batch}) # dropout=True\n",
    "            acc_test=accuracy.eval(feed_dict={X:Xtest,y:Ytest})\n",
    "            clear_output()\n",
    "            print(logits.eval(feed_dict={X:X_batch,y:y_batch})[0])\n",
    "            print(epoch+1,\"Train accuracy: \",acc_train,\" Test accuracy: \",acc_test,end=\"\\r\")\n",
    "            train_accuracy_save.append(acc_train)\n",
    "            test_accuracy_save.append(acc_test)\n",
    "        save_path=saver.save(sess,\"model_checkpoints/fert_cnn.ckpt\")\n",
    "\n",
    "    x_number=range(1,len(test_accuracy_save)+1)\n",
    "    plt.plot(x_number, train_accuracy_save, 'r--', x_number,test_accuracy_save)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-89026442c8a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-5db90ae60492>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;31m#augmenting the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mYtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mImageAug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain_u\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mYtrain_u\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maug_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcritical_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mn_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-cf143fc9b829>\u001b[0m in \u001b[0;36mImageAug\u001b[1;34m(Xtrain, Ytrain, aug_size, critical_val)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mImageAug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mYtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maug_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcritical_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input count :\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==0.1.13\n",
      "astor==0.6.2\n",
      "bleach==1.5.0\n",
      "gast==0.2.0\n",
      "grpcio==1.10.0\n",
      "html5lib==0.9999999\n",
      "Keras==2.1.5\n",
      "Markdown==2.6.11\n",
      "numpy==1.14.2\n",
      "protobuf==3.5.2.post1\n",
      "PyYAML==3.12\n",
      "scipy==1.0.1\n",
      "six==1.11.0\n",
      "tensorboard==1.7.0\n",
      "tensorflow-gpu==1.7.0\n",
      "termcolor==1.1.0\n",
      "tqdm==4.19.9\n",
      "Werkzeug==0.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
